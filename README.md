# Project AA_WeWantAToast

## Team:
- Laurenz Bihlmayer
- Leo Niggemann
- Manuel Heeren
- Tobias Wi√ümach

## Repo
- /data: includes datasets (uploaded in the Sciebo cloud, to not exceed the repository size limit)
    - sf_2019.csv - San Francisco data
    - sf_2019_prepared.csv  - cleaned data set (run 01_cleaning_and_preparation.ipynb)
    - sf_2019_full.csv - external dataset from lyft.com to get geo coordinates
    - weather_hourly.csv - weather data
    - weather_hourly_sf_prepared.csv - cleaned weather data (run 00_cleaning_weather_data.ipynb)
- /report: LaTex document data
- 00_cleaning_weather_data.ipynb: Cleans weather_hourly.csv. Output weather_hourly_sf_prepared.csv
- 01_cleaning_and_preparation.ipynb: Cleans sf_2019.csv. Output sf_2019_prepared.csv
- 10_descriptive_analysis.ipynb: Descriptive Analysis of bike and weather data. KPI-Calculations.
- 20_clustering.ipynb: Clustering the bike, weather and geo data with KNN.
- 30_prediction.ipynb: Prediction of the hourly demand.

## How to run
- download the content of the data folder from the Sciebo cloud: https://uni-koeln.sciebo.de/s/YpA5Bwn0a93SJsf
- install dependencies  (run 'pipenv install' in the current folder)
- run cleaning steps further steps depend on 00_cleaning_weather_data.ipynb and 01_cleaning_and_preparation.ipynb
- run 10_descriptive_analysis.ipynb, 20_clustering.ipynb, 30_prediction.ipynb as desired. No dependencies between these scripts