{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f026e41",
   "metadata": {},
   "source": [
    "# Cleaning of Weather Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ec38e0",
   "metadata": {},
   "source": [
    "Import data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75009f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# import data set \n",
    "df = pd.read_csv('data/weather_hourly_sf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d07ff6",
   "metadata": {},
   "source": [
    "Select a timeframe according to the bike sharing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93b4095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by date_time \n",
    "df.sort_values(by='date_time', ascending = True, inplace = True)\n",
    "# turn date_time to datetime format and adjust to time difference\n",
    "df['date_time'] = pd.to_datetime(df['date_time']) + timedelta(hours=-8)\n",
    "# range from 2019-01-31 to 2019-12-31\n",
    "df = df[(df['date_time'] >= '2019-01-01 00:00:00') & (df['date_time'] <= '2019-12-31 23:00:00')]\n",
    "# reset index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae0e40b",
   "metadata": {},
   "source": [
    "Check for NAs and duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "603314cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dd5c58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0d9a5a",
   "metadata": {},
   "source": [
    "Since there are no NAs left after slicing the dataframe, only duplicates have to be removed.\n",
    "\n",
    "Let's take a closer look at duplicates, especially duplicates in the date_time columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66ce6854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date_time'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53031b86",
   "metadata": {},
   "source": [
    "There are 79 duplicated rows across all collumns of the dataframe and 371 duplicated entries in the date_time cloumn.\n",
    "We do not want to drop columns easily here. Instead we will count how often temperature changes across the whole data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d48c40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    5301\n",
       "True     2735\n",
       "Name: max_temp, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if max_temp changes each row\n",
    "max_temp_change = df['max_temp'].diff().gt(0)\n",
    "max_temp_change.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "382fe18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    5296\n",
       "True     2740\n",
       "Name: min_temp, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if min_temp changes each row\n",
    "min_temp_change = df['min_temp'].diff().gt(0)\n",
    "min_temp_change.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747491e3",
   "metadata": {},
   "source": [
    "Temperature changes hourly at odds of roughly 2:1.\n",
    "Duplicated rows in the dataframe can therefore be a result of duplicated entries in the date_time column co-occuring with a natural steady temperature trend.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c60d127",
   "metadata": {},
   "source": [
    "Now we determine the expected number of entries in the dataframe (the dataframe starts at 2019-01-31) to check whether the number of entries does not exceed the number of expected entries considerably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d19cc30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8040\n"
     ]
    }
   ],
   "source": [
    "# calculate expected entries \n",
    "exp_length = (365-30) *24 \n",
    "print(exp_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea026f",
   "metadata": {},
   "source": [
    "We check the actual number of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89d53ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8036\n"
     ]
    }
   ],
   "source": [
    "act_length = len(df)\n",
    "print(act_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a759065",
   "metadata": {},
   "source": [
    "The actual and expected numbers are matching, except of 4 entries. Further, Temperature values tend to not change in the course of an hour at non-duplicates aswell, therefore we can not declare the duplicates as redundant data. We will keep the entries but adjust the date_time column. Dropping duplicates and interpolating new values is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65158125",
   "metadata": {},
   "source": [
    "The following function takes duplicated date_time entries as input and shifts these timestamps forward until no date_time duplicates remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed96f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn date_time to datetime format \n",
    "df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "# take duplicate timestamps and increase hour +1 while duplicate exists \n",
    "while any(df['date_time'].duplicated()) == True:\n",
    "    df['date_time'] = np.where(~df['date_time'].duplicated(), df['date_time'], df['date_time']+timedelta(hours=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "986a2a17",
   "metadata": {},
   "source": [
    "Finally, we save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8399de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "df.to_csv('data/weather_hourly_sf_prepared.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aawewantatoast-lnzi3lpw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac5622dfc5a39a541fac3bc7e754e9275b24250def9e44d62ed6fa5af0fc4611"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
